{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:56:08.832262Z","iopub.execute_input":"2025-12-01T08:56:08.832661Z","iopub.status.idle":"2025-12-01T08:56:09.120415Z","shell.execute_reply.started":"2025-12-01T08:56:08.832629Z","shell.execute_reply":"2025-12-01T08:56:09.119509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I will add an API key to my Kaggle Notebook.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"âœ… Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:56:18.481723Z","iopub.execute_input":"2025-12-01T08:56:18.482211Z","iopub.status.idle":"2025-12-01T08:56:18.752884Z","shell.execute_reply.started":"2025-12-01T08:56:18.482192Z","shell.execute_reply":"2025-12-01T08:56:18.751973Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now I want to import ADK components.","metadata":{}},{"cell_type":"code","source":"import json\nimport requests\nimport subprocess\nimport time\nimport uuid\n\nfrom google.adk.agents import Agent\nfrom google.adk.sessions import DatabaseSessionService\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import Runner\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.code_executors import BuiltInCodeExecutor\nfrom google.adk.tools import google_search, AgentTool, ToolContext\nfrom google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.adk.tools.mcp_tool.mcp_toolset import McpToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom mcp import StdioServerParameters\nfrom google.adk.apps.app import App, ResumabilityConfig\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.agents import LlmAgent\nfrom google.genai import types\n\n# Hide additional warnings in the notebook\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"âœ… ADK components imported successfully.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:57:43.074897Z","iopub.execute_input":"2025-12-01T08:57:43.075137Z","iopub.status.idle":"2025-12-01T08:57:43.082967Z","shell.execute_reply.started":"2025-12-01T08:57:43.075122Z","shell.execute_reply":"2025-12-01T08:57:43.081483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Configure Retry Options","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)\nprint(\"This code ran\")    # I like evidence my code ran","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:57:50.169010Z","iopub.execute_input":"2025-12-01T08:57:50.169896Z","iopub.status.idle":"2025-12-01T08:57:50.175094Z","shell.execute_reply.started":"2025-12-01T08:57:50.169876Z","shell.execute_reply":"2025-12-01T08:57:50.173590Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Creating a Reasearch Multi-Agent.","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"VeganResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"âœ… research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:57:54.416141Z","iopub.execute_input":"2025-12-01T08:57:54.417249Z","iopub.status.idle":"2025-12-01T08:57:54.422283Z","shell.execute_reply.started":"2025-12-01T08:57:54.417193Z","shell.execute_reply":"2025-12-01T08:57:54.421577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Creating Summarizing Agent.","metadata":{}},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"VeganSummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"âœ… summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:57:59.095993Z","iopub.execute_input":"2025-12-01T08:57:59.097192Z","iopub.status.idle":"2025-12-01T08:57:59.103148Z","shell.execute_reply.started":"2025-12-01T08:57:59.097151Z","shell.execute_reply":"2025-12-01T08:57:59.101580Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Root agent created.","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"VeganResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `VeganResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `VeganSummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"âœ… root_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:58:03.825324Z","iopub.execute_input":"2025-12-01T08:58:03.825710Z","iopub.status.idle":"2025-12-01T08:58:03.831113Z","shell.execute_reply.started":"2025-12-01T08:58:03.825694Z","shell.execute_reply":"2025-12-01T08:58:03.830058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"AgentTool to wrap the sub-agents to make them capable tools for the root agent.","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What is the latest information on the benefits of a Vegan diet?\"\n) \n\nresponse = await runner.run_debug(\n    \"Should you eat organic vegetables?\"\n)\n\nresponse = await runner.run_debug(\n    \"Are there Vegan cooking classes I can take?\"\n)\n\nresponse = await runner.run_debug(\n    \"Is it better for the planet if humans ate a plant based diet?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:58:08.649698Z","iopub.execute_input":"2025-12-01T08:58:08.650020Z","iopub.status.idle":"2025-12-01T08:58:43.614340Z","shell.execute_reply.started":"2025-12-01T08:58:08.650002Z","shell.execute_reply":"2025-12-01T08:58:43.613571Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Climate researcher agent created.","metadata":{}},{"cell_type":"code","source":"# Environment Researcher: Focuses on cattle grazing environmental comcerns.\nenvironment_researcher = Agent(\n    name=\"EnvironmentResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest trends on the effect grazing cattle for food has on the environment and the long term impact on the planet. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"environment_researcher\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"âœ… environment_researcher created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:24:47.644490Z","iopub.execute_input":"2025-12-01T09:24:47.644802Z","iopub.status.idle":"2025-12-01T09:24:47.650003Z","shell.execute_reply.started":"2025-12-01T09:24:47.644785Z","shell.execute_reply":"2025-12-01T09:24:47.649268Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Vegan AI research agent created.","metadata":{}},{"cell_type":"code","source":"# Vegan AI Researcher: Focuses on AI's role in fostering plant based eating..\nvegan_ai_researcher = Agent(\n    name=\"VeganAIResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent reports on how AI can help people change to a plant based diet. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"vegan_ai_researcher\",  # The result will be stored with this key.\n)\n\nprint(\"âœ… vegan_ai_researcher created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:24:52.352532Z","iopub.execute_input":"2025-12-01T09:24:52.352931Z","iopub.status.idle":"2025-12-01T09:24:52.359109Z","shell.execute_reply.started":"2025-12-01T09:24:52.352903Z","shell.execute_reply":"2025-12-01T09:24:52.358366Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the aggregate agent.","metadata":{}},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these two research findings into a single executive summary:\n\n    **EnvironmentTrends:**\n    {environment_researcher}\n    \n    **AI Breakthroughs:**\n    {vegan_ai_researcher}\n    \n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all two reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"âœ… aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:24:57.877142Z","iopub.execute_input":"2025-12-01T09:24:57.877369Z","iopub.status.idle":"2025-12-01T09:24:57.882049Z","shell.execute_reply.started":"2025-12-01T09:24:57.877356Z","shell.execute_reply":"2025-12-01T09:24:57.881204Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"All the created agents come together under a parrellel agent","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[environment_researcher, vegan_ai_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"âœ… Parallel and Sequential Agents created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:25:03.022148Z","iopub.execute_input":"2025-12-01T09:25:03.022496Z","iopub.status.idle":"2025-12-01T09:25:03.028984Z","shell.execute_reply.started":"2025-12-01T09:25:03.022479Z","shell.execute_reply":"2025-12-01T09:25:03.027434Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Running the parallel agent.","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the findings on Environment and Vegan.\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:25:07.596993Z","iopub.execute_input":"2025-12-01T09:25:07.597230Z","iopub.status.idle":"2025-12-01T09:25:17.768964Z","shell.execute_reply.started":"2025-12-01T09:25:07.597216Z","shell.execute_reply":"2025-12-01T09:25:17.768112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now I want to store information about me permanently in memory.","metadata":{}},{"cell_type":"markdown","source":"Creating a new memory agent.","metadata":{}},{"cell_type":"code","source":"APP_NAME = \"default\"  # Application\nUSER_ID = \"default\"  # User\nSESSION = \"default\"  # Session\n\nMODEL_NAME = \"gemini-2.5-flash-lite\"\n\n\n# Step 1: Create the LLM Agent\nroot_agent = Agent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"A text chatbot\",  # Description of the agent's purpose\n)\n\n# Step 2: Set up Session Management\n# InMemorySessionService stores conversations in RAM (temporary)\nsession_service = InMemorySessionService()\n\n# Step 3: Create the Runner\nrunner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"âœ… Stateful agent initialized!\")\nprint(f\"   - Application: {APP_NAME}\")\nprint(f\"   - User: {USER_ID}\")\nprint(f\"   - Using: {session_service.__class__.__name__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:25:44.631877Z","iopub.execute_input":"2025-12-01T09:25:44.632578Z","iopub.status.idle":"2025-12-01T09:25:44.639039Z","shell.execute_reply.started":"2025-12-01T09:25:44.632558Z","shell.execute_reply":"2025-12-01T09:25:44.638236Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Making the agent remember conversations.","metadata":{}},{"cell_type":"code","source":"# Create a new agent.\nvegan_chatbot_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"A text chatbot with persistent memory\",\n)\n\n# Step 2: Switch to DatabaseSessionService\n# SQLite database will be created automatically\ndb_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\nsession_service = DatabaseSessionService(db_url=db_url)\n\n# Step 3: Create a new runner with persistent storage\nrunner = Runner(agent=vegan_chatbot_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"âœ… Upgraded to persistent sessions!\")\nprint(f\"   - Database: my_agent_data.db\")\nprint(f\"   - Sessions will survive restarts!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:26:03.912011Z","iopub.execute_input":"2025-12-01T09:26:03.912323Z","iopub.status.idle":"2025-12-01T09:26:03.920740Z","shell.execute_reply.started":"2025-12-01T09:26:03.912307Z","shell.execute_reply":"2025-12-01T09:26:03.919825Z"}},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"Creating helper functions.","metadata":{}},{"cell_type":"code","source":"# Define helper functions used for this portion of my notebook.\nasync def run_session(\n    runner_instance: Runner,\n    user_queries: list[str] | str = None,\n    session_name: str = \"default\",\n):\n    print(f\"\\n ### Session: {session_name}\")\n\n    # Get app name from the Runner\n    app_name = runner_instance.app_name\n\n    # Attempt to create a new session or retrieve an existing one\n    try:\n        session = await session_service.create_session(\n            app_name=app_name, user_id=USER_ID, session_id=session_name\n        )\n    except:\n        session = await session_service.get_session(\n            app_name=app_name, user_id=USER_ID, session_id=session_name\n        )\n\n    # Process queries if provided\n    if user_queries:\n        # Convert single query to list for uniform processing\n        if type(user_queries) == str:\n            user_queries = [user_queries]\n\n        # Process each query in the list sequentially\n        for query in user_queries:\n            print(f\"\\nUser > {query}\")\n\n            # Convert the query string to the ADK Content format\n            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n\n            # Stream the agent's response asynchronously\n            async for event in runner_instance.run_async(\n                user_id=USER_ID, session_id=session.id, new_message=query\n            ):\n                # Check if the event contains valid content\n                if event.content and event.content.parts:\n                    # Filter out empty or \"None\" responses before printing\n                    if (\n                        event.content.parts[0].text != \"None\"\n                        and event.content.parts[0].text\n                    ):\n                        print(f\"{MODEL_NAME} > \", event.content.parts[0].text)\n    else:\n        print(\"No queries!\")\n\n\nprint(\"âœ… Helper functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:33:08.348974Z","iopub.execute_input":"2025-12-01T09:33:08.349251Z","iopub.status.idle":"2025-12-01T09:33:08.357523Z","shell.execute_reply.started":"2025-12-01T09:33:08.349234Z","shell.execute_reply":"2025-12-01T09:33:08.356265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Adding information.","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner,\n    [\"Hi, I am Jupiter and I'm a Vegan! What city has the most Vegan restaurants?\", \"Hello! What is my name?\"],\n    \"test-db-session-01\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:33:16.334767Z","iopub.execute_input":"2025-12-01T09:33:16.335664Z","iopub.status.idle":"2025-12-01T09:33:20.445426Z","shell.execute_reply.started":"2025-12-01T09:33:16.335635Z","shell.execute_reply":"2025-12-01T09:33:20.444292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Verifying Persistance","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner,\n    [\"Hello! What is my name?\", \"Am I a Vegan?\"],\n    \"test-db-session-01\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:37:06.941460Z","iopub.execute_input":"2025-12-01T09:37:06.941816Z","iopub.status.idle":"2025-12-01T09:37:09.439056Z","shell.execute_reply.started":"2025-12-01T09:37:06.941796Z","shell.execute_reply":"2025-12-01T09:37:09.438182Z"}},"outputs":[],"execution_count":null}]}